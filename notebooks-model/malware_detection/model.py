import os
import numpy as np
import pandas as pd
import json
import time
from datetime import datetime
from typing import Dict, Any, Optional, Union, List, Tuple
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Constants
MODEL_VERSION = "1.0.0"
MODEL_METADATA_FILENAME = "model_metadata.json"
TF_MODEL_FILENAME = "model.h5"
SCALER_FILENAME = "scaler.pkl"

# Configure TensorFlow for memory efficiency
tf.config.experimental.set_memory_growth(
    tf.config.list_physical_devices('GPU')[0], True
) if tf.config.list_physical_devices('GPU') else None

# For serverless environments, optimize TensorFlow
tf.config.threading.set_inter_op_parallelism_threads(1)
tf.config.threading.set_intra_op_parallelism_threads(1)

class Model:
    """Malware Detection Model using TensorFlow neural network.
    
    This model is designed to detect malicious files based on extracted features,
    using a deep neural network architecture optimized for binary classification.
    """
    
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.metadata = {
            "version": MODEL_VERSION,
            "created_at": None,
            "updated_at": None,
            "accuracy": None,
            "precision": None,
            "recall": None,
            "f1_score": None,
            "features": None,
            "architecture": "neural_network"
        }
        self._is_compiled = False
        self._model_cache = {}
    
    def _build_model(self, input_shape: Tuple[int], dropout_rate: float = 0.3) -> keras.Model:
        """Build the neural network architecture.
        
        Args:
            input_shape: Shape of input features
            dropout_rate: Dropout rate for regularization
            
        Returns:
            Compiled Keras model
        """
        model = keras.Sequential([
            layers.Input(shape=input_shape),
            
            # First hidden layer
            layers.Dense(128, kernel_regularizer=regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.LeakyReLU(alpha=0.1),
            layers.Dropout(dropout_rate),
            
            # Second hidden layer
            layers.Dense(64, kernel_regularizer=regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.LeakyReLU(alpha=0.1),
            layers.Dropout(dropout_rate),
            
            # Third hidden layer
            layers.Dense(32, kernel_regularizer=regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.LeakyReLU(alpha=0.1),
            layers.Dropout(dropout_rate),
            
            # Output layer
            layers.Dense(1, activation='sigmoid')
        ])
        
        # Compile the model
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=[
                'accuracy',
                keras.metrics.Precision(),
                keras.metrics.Recall(),
                keras.metrics.AUC()
            ]
        )
        
        return model
    
    def train(self, X, y, validation_split=0.2, epochs=50, batch_size=32, 
              early_stopping_patience=10, model_checkpoint_path=None, verbose=1,
              class_weights=None):
        """Train the malware detection model.
        
        Args:
            X: Features for training
            y: Target labels (0 for benign, 1 for malware)
            validation_split: Fraction of data to use for validation
            epochs: Maximum number of training epochs
            batch_size: Batch size for training
            early_stopping_patience: Patience for early stopping
            model_checkpoint_path: Path to save model checkpoints
            verbose: Verbosity level for training
            class_weights: Weights for handling class imbalance
            
        Returns:
            self: Trained model instance
        """
        # Normalize features
        X_scaled = self.scaler.fit_transform(X)
        
        # Build the model
        input_shape = (X.shape[1],)
        self.model = self._build_model(input_shape)
        self._is_compiled = True
        
        # Set up callbacks
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=early_stopping_patience,
                restore_best_weights=True
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.2,
                patience=5,
                min_lr=0.0001
            )
        ]
        
        # Add model checkpoint if path provided
        if model_checkpoint_path:
            os.makedirs(os.path.dirname(model_checkpoint_path), exist_ok=True)
            callbacks.append(ModelCheckpoint(
                model_checkpoint_path,
                monitor='val_loss',
                save_best_only=True
            ))
        
        # Train the model
        history = self.model.fit(
            X_scaled, y,
            validation_split=validation_split,
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=verbose,
            class_weight=class_weights
        )
        
        # Update metadata
        self.metadata["created_at"] = datetime.now().isoformat()
        self.metadata["updated_at"] = datetime.now().isoformat()
        
        # Store feature names if available
        if hasattr(X, 'columns'):
            self.metadata["features"] = list(X.columns)
        
        # Get final metrics from training history
        final_epoch = len(history.history['val_loss']) - 1
        if final_epoch >= 0:
            self.metadata["accuracy"] = float(history.history['val_accuracy'][final_epoch])
            self.metadata["precision"] = float(history.history['val_precision'][final_epoch])
            self.metadata["recall"] = float(history.history['val_recall'][final_epoch])
        
        return self
    
    def predict(self, X, threshold=0.5, return_probabilities=False, use_cache=True):
        """Make predictions on new data.
        
        Args:
            X: Features for prediction
            threshold: Classification threshold
            return_probabilities: Whether to return probabilities instead of classes
            use_cache: Whether to use prediction cache (if available)
            
        Returns:
            NumPy array of predictions (0 for benign, 1 for malware) or probabilities
        """
        if self.model is None:
            raise ValueError('Model not trained or loaded yet')
        
        # Check cache if enabled
        if use_cache and hasattr(X, '__hash__') and X.__hash__ is not None:
            cache_key = hash(X.tobytes()) if hasattr(X, 'tobytes') else None
            if cache_key in self._model_cache:
                return self._model_cache[cache_key]
        
        # Scale features
        X_scaled = self.scaler.transform(X)
        
        # Get predictions
        probabilities = self.model.predict(X_scaled, verbose=0)
        
        # Cache result if caching is enabled
        if use_cache and hasattr(X, '__hash__') and X.__hash__ is not None:
            cache_key = hash(X.tobytes()) if hasattr(X, 'tobytes') else None
            if cache_key is not None:
                self._model_cache[cache_key] = probabilities
        
        if return_probabilities:
            return probabilities
        else:
            return (probabilities >= threshold).astype(int)
    
    def predict_with_details(self, X, threshold=0.5):
        """Make predictions with detailed confidence information.
        
        Args:
            X: Features for prediction
            threshold: Classification threshold
            
        Returns:
            List of dictionaries with prediction details
        """
        if self.model is None:
            raise ValueError('Model not trained or loaded yet')
        
        # Scale features
        X_scaled = self.scaler.transform(X)
        
        # Get predictions
        probabilities = self.model.predict(X_scaled, verbose=0)
        
        # Format results
        results = []
        for i, prob in enumerate(probabilities):
            malware_prob = float(prob[0])
            result = {
                "is_malware": malware_prob >= threshold,
                "confidence": malware_prob,
                "threshold_used": threshold,
                "prediction_source": "model"
            }
            results.append(result)
        
        return results

    def load(self, path):
        """Load model from disk.
        
        Args:
            path: Path to model directory or file
            
        Returns:
            self: Model instance with loaded model
        """
        if os.path.isdir(path):
            # Load from directory
            model_path = os.path.join(path, TF_MODEL_FILENAME)
            scaler_path = os.path.join(path, SCALER_FILENAME)
            metadata_path = os.path.join(path, MODEL_METADATA_FILENAME)
            
            # Load TensorFlow model
            self.model = keras.models.load_model(model_path)
            self._is_compiled = True
            
            # Load scaler if exists
            if os.path.exists(scaler_path):
                import joblib
                self.scaler = joblib.load(scaler_path)
            
            # Load metadata if exists
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r') as f:
                    self.metadata = json.load(f)
        else:
            # Load just the model file
            self.model = keras.models.load_model(path)
            self._is_compiled = True
        
        # Clear prediction cache
        self._model_cache = {}
        
        return self

    def save(self, path):
        """Save model to disk.
        
        Args:
            path: Directory path to save the model
            
        Returns:
            str: Path where model was saved
        """
        if self.model is None:
            raise ValueError("Model not trained or loaded yet")
        
        # Create directory if it doesn't exist
        os.makedirs(path, exist_ok=True)
        
        # Update metadata
        self.metadata["updated_at"] = datetime.now().isoformat()
        
        # Save TensorFlow model
        model_path = os.path.join(path, TF_MODEL_FILENAME)
        self.model.save(model_path, save_format='h5')
        
        # Save scaler
        import joblib
        scaler_path = os.path.join(path, SCALER_FILENAME)
        joblib.dump(self.scaler, scaler_path)
        
        # Save metadata
        metadata_path = os.path.join(path, MODEL_METADATA_FILENAME)
        with open(metadata_path, 'w') as f:
            json.dump(self.metadata, f, indent=2)
        
        return path
    
    def clear_cache(self):
        """Clear the prediction cache."""
        self._model_cache = {}
    
    def optimize_for_inference(self):
        """Optimize the model for inference.
        
        This method applies TensorFlow optimizations to make the model
        more efficient for deployment environments.
        
        Returns:
            self: Optimized model instance
        """
        if self.model is None:
            raise ValueError("Model not trained or loaded yet")
        
        # Save and reload model to ensure optimizations are applied
        temp_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 
                               "temp_model.h5")
        self.model.save(temp_path, save_format='h5')
        self.model = keras.models.load_model(temp_path)
        
        # Cleanup temp file
        if os.path.exists(temp_path):
            os.remove(temp_path)
        
        # Clear prediction cache
        self.clear_cache()
        
        return self
    
    def update_metrics(self, accuracy=None, precision=None, recall=None, f1_score=None):
        """Update model performance metrics.
        
        Args:
            accuracy: Accuracy score
            precision: Precision score
            recall: Recall score
            f1_score: F1 score
            
        Returns:
            self: Model instance with updated metadata
        """
        if accuracy is not None:
            self.metadata["accuracy"] = accuracy
        if precision is not None:
            self.metadata["precision"] = precision
        if recall is not None:
            self.metadata["recall"] = recall
        if f1_score is not None:
            self.metadata["f1_score"] = f1_score
            
        self.metadata["updated_at"] = datetime.now().isoformat()
        return self
    
    def get_version(self):
        """Get the model version.
        
        Returns:
            str: Version string
        """
        return self.metadata["version"]
